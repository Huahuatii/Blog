const s=JSON.parse(`{"key":"v-cc165fd2","path":"/zh/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Tensorboard.html","title":"Tensorboard","lang":"zh-CN","frontmatter":{"title":"Tensorboard","date":"2023-03-13T00:00:00.000Z","tag":["Deep Learning","Tensorboard"],"category":["深度学习"],"description":"数据处理 def contrastive_loss(z, labels, margin=1.0): ''' z是隐空间中的编码，labels是样本的标签 计算同类样本对和异类样本对 ''' n_samples = z.shape[0] same_class_mask = (labels.view(n_samples, 1) == labels.view(1, n_samples)) diff_class_mask = ~ same_class_mask same_class_indices = torch.where(same_class_mask) diff_class_indices = torch.where(diff_class_mask) same_class_pairs = list(zip(same_class_indices[0], same_class_indices[1])) diff_class_pairs = list(zip(diff_class_indices[0], diff_class_indices[1])) # 计算同类样本对的损失函数 same_class_losses = [] for i, j in same_class_pairs: dist = torch.norm(z[i] - z[j]) same_class_losses.append(dist ** 2) same_class_loss = torch.mean(torch.stack(same_class_losses)) # 计算异类样本对的损失函数 diff_class_losses = [] for i, j in diff_class_pairs: dist = torch.norm(z[i] - z[j]) diff_class_losses.append(F.relu(margin - dist) ** 2) diff_class_loss = torch.mean(torch.stack(diff_class_losses)) # 添加正则项 # reg_loss = 0.0 # for param in model.parameters(): # reg_loss += torch.sum(param ** 2) # 将所有损失函数加权求和，并返回最终的损失值 total_loss = same_class_loss + diff_class_loss # + 0.01 * reg_loss return total_loss","head":[["link",{"rel":"alternate","hreflang":"en-us","href":"https://Huahuatii.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Tensorboard.html"}],["meta",{"property":"og:url","content":"https://Huahuatii.github.io/zh/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Tensorboard.html"}],["meta",{"property":"og:site_name","content":"胡图图的垃圾站"}],["meta",{"property":"og:title","content":"Tensorboard"}],["meta",{"property":"og:description","content":"数据处理 def contrastive_loss(z, labels, margin=1.0): ''' z是隐空间中的编码，labels是样本的标签 计算同类样本对和异类样本对 ''' n_samples = z.shape[0] same_class_mask = (labels.view(n_samples, 1) == labels.view(1, n_samples)) diff_class_mask = ~ same_class_mask same_class_indices = torch.where(same_class_mask) diff_class_indices = torch.where(diff_class_mask) same_class_pairs = list(zip(same_class_indices[0], same_class_indices[1])) diff_class_pairs = list(zip(diff_class_indices[0], diff_class_indices[1])) # 计算同类样本对的损失函数 same_class_losses = [] for i, j in same_class_pairs: dist = torch.norm(z[i] - z[j]) same_class_losses.append(dist ** 2) same_class_loss = torch.mean(torch.stack(same_class_losses)) # 计算异类样本对的损失函数 diff_class_losses = [] for i, j in diff_class_pairs: dist = torch.norm(z[i] - z[j]) diff_class_losses.append(F.relu(margin - dist) ** 2) diff_class_loss = torch.mean(torch.stack(diff_class_losses)) # 添加正则项 # reg_loss = 0.0 # for param in model.parameters(): # reg_loss += torch.sum(param ** 2) # 将所有损失函数加权求和，并返回最终的损失值 total_loss = same_class_loss + diff_class_loss # + 0.01 * reg_loss return total_loss"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:locale:alternate","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2023-04-04T05:30:56.000Z"}],["meta",{"property":"article:tag","content":"Deep Learning"}],["meta",{"property":"article:tag","content":"Tensorboard"}],["meta",{"property":"article:published_time","content":"2023-03-13T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-04-04T05:30:56.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Tensorboard\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-03-13T00:00:00.000Z\\",\\"dateModified\\":\\"2023-04-04T05:30:56.000Z\\",\\"author\\":[]}"]]},"headers":[],"git":{"createdTime":1680586256000,"updatedTime":1680586256000,"contributors":[{"name":"Huahuatii","email":"2218653280@qq.com","commits":1}]},"readingTime":{"minutes":0.65,"words":195},"filePathRelative":"zh/posts/深度学习/Tensorboard.md","localizedDate":"2023年3月13日","excerpt":"<h1> 数据处理</h1>\\n<div class=\\"language-python line-numbers-mode\\" data-ext=\\"py\\"><pre class=\\"language-python\\"><code><span class=\\"token keyword\\">def</span> <span class=\\"token function\\">contrastive_loss</span><span class=\\"token punctuation\\">(</span>z<span class=\\"token punctuation\\">,</span> labels<span class=\\"token punctuation\\">,</span> margin<span class=\\"token operator\\">=</span><span class=\\"token number\\">1.0</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">:</span>\\n    <span class=\\"token triple-quoted-string string\\">'''\\n    z是隐空间中的编码，labels是样本的标签\\n    计算同类样本对和异类样本对\\n    '''</span>\\n    n_samples <span class=\\"token operator\\">=</span> z<span class=\\"token punctuation\\">.</span>shape<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">]</span>\\n    same_class_mask <span class=\\"token operator\\">=</span> <span class=\\"token punctuation\\">(</span>labels<span class=\\"token punctuation\\">.</span>view<span class=\\"token punctuation\\">(</span>n_samples<span class=\\"token punctuation\\">,</span> <span class=\\"token number\\">1</span><span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">==</span> labels<span class=\\"token punctuation\\">.</span>view<span class=\\"token punctuation\\">(</span><span class=\\"token number\\">1</span><span class=\\"token punctuation\\">,</span> n_samples<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    diff_class_mask <span class=\\"token operator\\">=</span> <span class=\\"token operator\\">~</span> same_class_mask\\n    same_class_indices <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>where<span class=\\"token punctuation\\">(</span>same_class_mask<span class=\\"token punctuation\\">)</span>\\n    diff_class_indices <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>where<span class=\\"token punctuation\\">(</span>diff_class_mask<span class=\\"token punctuation\\">)</span>\\n    same_class_pairs <span class=\\"token operator\\">=</span> <span class=\\"token builtin\\">list</span><span class=\\"token punctuation\\">(</span><span class=\\"token builtin\\">zip</span><span class=\\"token punctuation\\">(</span>same_class_indices<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> same_class_indices<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">1</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    diff_class_pairs <span class=\\"token operator\\">=</span> <span class=\\"token builtin\\">list</span><span class=\\"token punctuation\\">(</span><span class=\\"token builtin\\">zip</span><span class=\\"token punctuation\\">(</span>diff_class_indices<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">0</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">,</span> diff_class_indices<span class=\\"token punctuation\\">[</span><span class=\\"token number\\">1</span><span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token comment\\"># 计算同类样本对的损失函数</span>\\n    same_class_losses <span class=\\"token operator\\">=</span> <span class=\\"token punctuation\\">[</span><span class=\\"token punctuation\\">]</span>\\n    <span class=\\"token keyword\\">for</span> i<span class=\\"token punctuation\\">,</span> j <span class=\\"token keyword\\">in</span> same_class_pairs<span class=\\"token punctuation\\">:</span>\\n        dist <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>norm<span class=\\"token punctuation\\">(</span>z<span class=\\"token punctuation\\">[</span>i<span class=\\"token punctuation\\">]</span> <span class=\\"token operator\\">-</span> z<span class=\\"token punctuation\\">[</span>j<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span>\\n        same_class_losses<span class=\\"token punctuation\\">.</span>append<span class=\\"token punctuation\\">(</span>dist <span class=\\"token operator\\">**</span> <span class=\\"token number\\">2</span><span class=\\"token punctuation\\">)</span>\\n    same_class_loss <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>mean<span class=\\"token punctuation\\">(</span>torch<span class=\\"token punctuation\\">.</span>stack<span class=\\"token punctuation\\">(</span>same_class_losses<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token comment\\"># 计算异类样本对的损失函数</span>\\n    diff_class_losses <span class=\\"token operator\\">=</span> <span class=\\"token punctuation\\">[</span><span class=\\"token punctuation\\">]</span>\\n    <span class=\\"token keyword\\">for</span> i<span class=\\"token punctuation\\">,</span> j <span class=\\"token keyword\\">in</span> diff_class_pairs<span class=\\"token punctuation\\">:</span>\\n        dist <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>norm<span class=\\"token punctuation\\">(</span>z<span class=\\"token punctuation\\">[</span>i<span class=\\"token punctuation\\">]</span> <span class=\\"token operator\\">-</span> z<span class=\\"token punctuation\\">[</span>j<span class=\\"token punctuation\\">]</span><span class=\\"token punctuation\\">)</span>\\n        diff_class_losses<span class=\\"token punctuation\\">.</span>append<span class=\\"token punctuation\\">(</span>F<span class=\\"token punctuation\\">.</span>relu<span class=\\"token punctuation\\">(</span>margin <span class=\\"token operator\\">-</span> dist<span class=\\"token punctuation\\">)</span> <span class=\\"token operator\\">**</span> <span class=\\"token number\\">2</span><span class=\\"token punctuation\\">)</span>\\n    diff_class_loss <span class=\\"token operator\\">=</span> torch<span class=\\"token punctuation\\">.</span>mean<span class=\\"token punctuation\\">(</span>torch<span class=\\"token punctuation\\">.</span>stack<span class=\\"token punctuation\\">(</span>diff_class_losses<span class=\\"token punctuation\\">)</span><span class=\\"token punctuation\\">)</span>\\n    <span class=\\"token comment\\"># 添加正则项</span>\\n    <span class=\\"token comment\\"># reg_loss = 0.0</span>\\n    <span class=\\"token comment\\"># for param in model.parameters():</span>\\n    <span class=\\"token comment\\">#     reg_loss += torch.sum(param ** 2)</span>\\n    <span class=\\"token comment\\"># 将所有损失函数加权求和，并返回最终的损失值</span>\\n    total_loss <span class=\\"token operator\\">=</span> same_class_loss <span class=\\"token operator\\">+</span> diff_class_loss <span class=\\"token comment\\"># + 0.01 * reg_loss</span>\\n    <span class=\\"token keyword\\">return</span> total_loss\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}`);export{s as data};
