import{_ as n,W as s,X as a,a1 as p}from"./framework-179f767b.js";const t={},e=p(`<h1 id="从0开始搭建auto-encoder" tabindex="-1"><a class="header-anchor" href="#从0开始搭建auto-encoder" aria-hidden="true">#</a> 从0开始搭建Auto-Encoder</h1><p>搭建Auto-Encoder模型的时候，选择了更加结构化的搭建模式：</p><ol><li>搭建base_ae：这一步用来确定一个ae模型的基本结构会有哪些（其中有部分未必会用到）</li></ol><h2 id="_1-搭建base-ae模型" tabindex="-1"><a class="header-anchor" href="#_1-搭建base-ae模型" aria-hidden="true">#</a> 1 搭建base_AE模型</h2><ul><li>初始化</li><li>编码函数</li><li>解码函数</li><li>采样函数</li><li>生成函数</li><li>前向传播（抽象方法）</li><li>损失函数（抽象方法）</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;base_ae.py&#39;</span>
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> abc <span class="token keyword">import</span> abstractmethod  <span class="token comment"># 定义抽象方法</span>
<span class="token keyword">from</span> typing <span class="token keyword">import</span> TypeVar  <span class="token comment"># 定义数据类新的接口</span>
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Any
Tensor <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&#39;torch.tensor&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 定义泛型变量，表示一个 PyTorch 的 tensor</span>


<span class="token keyword">class</span> <span class="token class-name">BaseAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># 初始化神经网络模型的各个组件</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BaseAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>  <span class="token comment"># 定义一个编码过程</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>  <span class="token comment"># 定义一个解码过程</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> current_device<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义一个采样方法</span>
        <span class="token keyword">raise</span> RuntimeWarning<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义一个生成方法</span>
        <span class="token keyword">raise</span> NotImplementedError
        
    <span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># 定义初始化权重方法</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token decorator annotation punctuation">@abstractmethod</span>  <span class="token comment"># 装饰器，声明下面的方法为抽象方法</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义前向传播过程</span>
        <span class="token keyword">pass</span>

    <span class="token decorator annotation punctuation">@abstractmethod</span>
    <span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义损失函数</span>
        <span class="token keyword">pass</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">细节补充</p><p><code>sample</code>：该方法通常需要从一个潜在空间中随机采样一个向量，然后使用解码器将该向量转换为一个输出。</p><p><code>generate</code> ：该方法是用来生成一个输出的，它接收一个潜在空间中的向量作为输入，然后使用解码器将这个向量转换为一个输出。</p><p><mark><code>abstractmethod</code></mark>：具有抽象方法的类叫做抽象类（不可被实例化），可以通过在方法定义中添加装饰器<code>@abstractmethod</code>来将一个方法标记为抽象方法，通常在父类中直接写pass（否则直接子类没有写抽象方法也会直接继承该方法），所以子类必须必须重新覆盖该抽象方法，才能被实例化。</p></div><h2 id="_2-搭建具体ae模型" tabindex="-1"><a class="header-anchor" href="#_2-搭建具体ae模型" aria-hidden="true">#</a> 2 搭建具体AE模型</h2><ul><li>继承</li><li>添加层</li><li>初始化权重</li><li></li></ul><details class="hint-container details"><summary>Details</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;ae.py&#39;</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> TypeVar
<span class="token keyword">from</span> model<span class="token punctuation">.</span>base_ae <span class="token keyword">import</span> BaseAE

Tensor <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&#39;torch.tensor&#39;</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">AE</span><span class="token punctuation">(</span>BaseAE<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>  <span class="token comment"># AE的构造函数</span>
                 input_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 latent_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 hidden_dims<span class="token punctuation">:</span> List <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
                 dop<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
                 noise_flag<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>latent_dim <span class="token operator">=</span> latent_dim
        self<span class="token punctuation">.</span>noise_flag <span class="token operator">=</span> noise_flag
        self<span class="token punctuation">.</span>dop <span class="token operator">=</span> dop

        <span class="token keyword">if</span> hidden_dims <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span>

        <span class="token comment"># build encoder</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 添加第一个隐藏层</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 循环添加中间隐藏层</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 添加最后一个隐藏层，输出维度为latent_dim</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 将以上层组成encoder</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        <span class="token comment"># build decoder(同encoder)</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        hidden_dims2 <span class="token operator">=</span> hidden_dims<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 确保encoder和decoder层对称</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>final_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 调用初始化权重方法</span>
        initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 编码输出隐藏层结果</span>
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>noise_flag <span class="token keyword">and</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span> <span class="token comment"># 判断噪音tag/训练模式-&gt;是否添加噪音</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>
                <span class="token builtin">input</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">)</span> <span class="token comment"># 隐藏层的位置添加0.05的噪音</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> latent_code

    <span class="token comment"># 解码输出最终结果</span>
    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>final_layer<span class="token punctuation">(</span>embed<span class="token punctuation">)</span>

        <span class="token keyword">return</span> outputs

    <span class="token comment"># 前向传播，返回三个参数[输入值，隐藏值，重构值]</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">,</span> z<span class="token punctuation">]</span>

    <span class="token comment"># 定义损失函数(MSE(均方误差))</span>
    <span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        recons <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        recons_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> recons<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> recons_loss

        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">&#39;recons_loss&#39;</span><span class="token punctuation">:</span> recons_loss<span class="token punctuation">}</span>

    <span class="token comment"># 定义采样的函数（在隐藏层随机采样）</span>
    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_samples<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> current_device<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
               <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_samples<span class="token punctuation">,</span> self<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span>

        z <span class="token operator">=</span> z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>current_device<span class="token punctuation">)</span>
        samples <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

        <span class="token keyword">return</span> samples

    
    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Initialize weights using Xavier initialization</span>
    <span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">细节补充</p></div></details><h2 id="_3-调用模型进行训练-这里以网格搜索参数法为例" tabindex="-1"><a class="header-anchor" href="#_3-调用模型进行训练-这里以网格搜索参数法为例" aria-hidden="true">#</a> 3 调用模型进行训练（这里以网格搜索参数法为例）</h2><ul><li>传入模型结构及参数</li><li>读取预测数据集</li><li>实例化模型</li><li>TensorBoard可视化训练过程（可选）</li><li>输出模型信息（可选）</li><li>训练过程</li></ul><details class="hint-container details"><summary>Details</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;train_ae.py&#39;</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> csv
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> random_split
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> StepLR

<span class="token keyword">from</span> math <span class="token keyword">import</span> ceil
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> ParameterGrid

<span class="token keyword">from</span> model<span class="token punctuation">.</span>ae <span class="token keyword">import</span> AE
<span class="token keyword">from</span> route<span class="token punctuation">.</span>route <span class="token keyword">import</span> set_seed<span class="token punctuation">,</span> read_uq_arr<span class="token punctuation">,</span> myDataset



<span class="token comment"># 设定随机种子</span>
set_seed<span class="token punctuation">(</span><span class="token number">2029</span><span class="token punctuation">)</span>

<span class="token comment"># gpu训练</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>


<span class="token comment"># 网格参数</span>
param_grid  <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&#39;input_dim&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1126</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">502</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;learning_rate&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">,</span> <span class="token number">0.0005</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;latent_dim&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;hidden_dims&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;dop&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;gamma&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;noise_flag&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>


<span class="token comment"># 加载数据</span>
BC32_uq1126 <span class="token operator">=</span> read_uq_arr<span class="token punctuation">(</span><span class="token string">&#39;BC32&#39;</span><span class="token punctuation">,</span> gene_num<span class="token operator">=</span><span class="token number">1126</span><span class="token punctuation">)</span>  <span class="token comment"># 读取数据</span>
data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>BC32_uq1126<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  <span class="token comment"># 将arr数据转为tensor</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 将数据挪到GPU上</span>
dataset <span class="token operator">=</span> myDataset<span class="token punctuation">(</span>data<span class="token punctuation">)</span>  <span class="token comment"># 构建数据集</span>
train_size <span class="token operator">=</span> ceil<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.8</span><span class="token punctuation">)</span>  <span class="token comment"># 划分训练集大小</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">-</span> train_size  <span class="token comment"># 划分测试集大小</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> random_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 根据上述打乱数据集</span>

<span class="token comment"># 定义最优损失和参数</span>
best_loss <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">&#39;inf&#39;</span><span class="token punctuation">)</span>
best_params <span class="token operator">=</span> <span class="token boolean">None</span>

<span class="token comment"># 网格化搜索</span>
<span class="token keyword">for</span> params <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>ParameterGrid<span class="token punctuation">(</span>param_grid<span class="token punctuation">)</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                              batch_size<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                              shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>
                             batch_size<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                             shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment"># 使用当前参数训练模型</span>
    model <span class="token operator">=</span> AE<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;input_dim&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> latent_dim<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;latent_dim&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;hidden_dims&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dop<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;dop&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> noise_flag<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;noise_flag&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    
    <span class="token comment"># 打印训练信息</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\t----------------------------- INFO -------------------------------&quot;</span><span class="token punctuation">)</span>
    total_params <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Number of parameters: </span><span class="token interpolation"><span class="token punctuation">{</span>total_params<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Parameters: </span><span class="token interpolation"><span class="token punctuation">{</span>params<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\\t----------------------------- END --------------------------------&quot;</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 使用当前参数训练模型</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;learning_rate&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> model<span class="token punctuation">.</span>loss_function<span class="token punctuation">(</span><span class="token punctuation">)</span>
    scheduler <span class="token operator">=</span> StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;gamma&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 训练模型</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> inputs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> _ <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> model<span class="token punctuation">.</span>loss_function<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">]</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        train_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

        <span class="token comment"># 测试模型</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        test_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> inputs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> _ <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> model<span class="token punctuation">.</span>loss_function<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">]</span>
                test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            test_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

        <span class="token comment"># 更新学习率</span>
        scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 打印训练日志</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>
            <span class="token string-interpolation"><span class="token string">f&#39;Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">500</span><span class="token punctuation">}</span></span><span class="token string">, Train Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">, Test Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 将训练结果保存为一个tsv文件，用于查看参数以及训练结果</span>
        <span class="token keyword">if</span> epoch<span class="token operator">+</span><span class="token number">1</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&#39;result.tsv&#39;</span><span class="token punctuation">,</span><span class="token string">&#39;a&#39;</span><span class="token punctuation">,</span>newline<span class="token operator">=</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
                fields <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&#39;gamma&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;dop&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;noise_flag&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;input_dim&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;hidden_dims&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;learning_rate&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;test_loss&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;latent_dim&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">}</span>
                writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>DictWriter<span class="token punctuation">(</span>f<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">&#39;\\t&#39;</span><span class="token punctuation">,</span> fieldnames<span class="token operator">=</span>fields<span class="token punctuation">)</span>
                <span class="token comment"># writer.writeheader()</span>
                result <span class="token operator">=</span> params<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
                result<span class="token punctuation">[</span><span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
                result<span class="token punctuation">[</span><span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>train_loss<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
                result<span class="token punctuation">[</span><span class="token string">&#39;test_loss&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>test_loss<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span>result<span class="token punctuation">)</span>
                
    <span class="token comment"># 保存最好的参数组合</span>
    <span class="token keyword">if</span> test_loss <span class="token operator">&lt;</span> best_loss<span class="token punctuation">:</span>
        best_loss <span class="token operator">=</span> test_loss
        best_params <span class="token operator">=</span> params
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;./saved/ae/ae_model.pt&#39;</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;最佳参数组合：&quot;</span><span class="token punctuation">,</span> best_params<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;最佳测试损失：&quot;</span><span class="token punctuation">,</span> best_loss<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>附\`route.py\`</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;route.py&#39;</span>
<span class="token keyword">import</span> scanpy <span class="token keyword">as</span> sc
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> pickle<span class="token punctuation">,</span> json
<span class="token keyword">from</span> typing <span class="token keyword">import</span> TypeVar<span class="token punctuation">,</span> List<span class="token punctuation">,</span> Any
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset

Array <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&quot;numpy.adarray&quot;</span><span class="token punctuation">)</span>
base_dir <span class="token operator">=</span> <span class="token string">&quot;/home/hht/Myapps/Transfer_Project/data/&quot;</span>


<span class="token comment"># 设定随机种子</span>
<span class="token keyword">def</span> <span class="token function">set_seed</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>


<span class="token comment"># 对array数据进行标准化</span>
<span class="token keyword">def</span> <span class="token function">get_normed_array</span><span class="token punctuation">(</span>arr<span class="token punctuation">:</span> Array<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Array<span class="token punctuation">:</span>
    np<span class="token punctuation">.</span>seterr<span class="token punctuation">(</span>divide<span class="token operator">=</span><span class="token string">&#39;ignore&#39;</span><span class="token punctuation">,</span> invalid<span class="token operator">=</span><span class="token string">&#39;ignore&#39;</span><span class="token punctuation">)</span>
    means <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>arr<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    stds <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>arr<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    stds <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>stds <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> stds<span class="token punctuation">)</span>
    standardized_arr <span class="token operator">=</span> <span class="token punctuation">(</span>arr <span class="token operator">-</span> means<span class="token punctuation">)</span> <span class="token operator">/</span> stds
    <span class="token keyword">return</span> standardized_arr


<span class="token comment"># 计算混淆矩阵</span>
<span class="token keyword">def</span> <span class="token function">confusion_matrix</span><span class="token punctuation">(</span>predicted_labels<span class="token punctuation">,</span> true_labels<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    cm <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    num_samples <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>predicted_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        cm<span class="token punctuation">[</span>predicted_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> true_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        num_samples<span class="token punctuation">[</span>true_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> cm<span class="token punctuation">,</span> num_samples


<span class="token comment"># 计算准确率</span>
<span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> cm<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># 计算召回率</span>
<span class="token keyword">def</span> <span class="token function">recall</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>cm<span class="token punctuation">)</span> <span class="token operator">/</span> cm<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">weighted_recall</span><span class="token punctuation">(</span>cm<span class="token punctuation">,</span> num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    r <span class="token operator">=</span> recall<span class="token punctuation">(</span>cm<span class="token punctuation">)</span>
    w <span class="token operator">=</span> num_samples <span class="token operator">/</span> num_samples<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    avg_recall <span class="token operator">=</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>r<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
    <span class="token keyword">return</span> avg_recall


<span class="token comment"># 计算精确率</span>
<span class="token keyword">def</span> <span class="token function">precision</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>cm<span class="token punctuation">)</span> <span class="token operator">/</span> cm<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">weighted_precision</span><span class="token punctuation">(</span>cm<span class="token punctuation">,</span> num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_classes <span class="token operator">=</span> cm<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    precisions <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> num_samples<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            precisions<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> cm<span class="token punctuation">[</span>i<span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">/</span> cm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    avg_precision <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>
        precisions <span class="token operator">*</span> num_samples<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span>
    <span class="token keyword">return</span> avg_precision


<span class="token comment"># 计算F1值</span>
<span class="token keyword">def</span> <span class="token function">f1_score</span><span class="token punctuation">(</span>precision<span class="token punctuation">,</span> recall<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span> <span class="token operator">*</span> precision <span class="token operator">*</span> recall <span class="token operator">/</span> <span class="token punctuation">(</span>precision <span class="token operator">+</span> recall<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">weighted_f1_score</span><span class="token punctuation">(</span>avg_precision<span class="token punctuation">,</span> avg_recall<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span> <span class="token operator">*</span> avg_precision <span class="token operator">*</span> avg_recall <span class="token operator">/</span> <span class="token punctuation">(</span>avg_precision <span class="token operator">+</span> avg_recall<span class="token punctuation">)</span>


<span class="token comment"># 设定所需的common_gene</span>
<span class="token keyword">def</span> <span class="token function">choose_common_gene</span><span class="token punctuation">(</span>gene_num<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> gene_num <span class="token operator">==</span> <span class="token number">1729</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;Mart/common_uq_geneID_1729.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            cols_to_keep <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> gene_num <span class="token operator">==</span> <span class="token number">1126</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;Mart/common_uq_geneID_1126.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            cols_to_keep <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> gene_num <span class="token operator">==</span> <span class="token number">1416</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;Mart/common_uq_geneID_1416.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            cols_to_keep <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">&quot;输入正确gene_num&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cols_to_keep


<span class="token comment"># 根据所需的特定基因读取数据的标准化arr</span>
<span class="token keyword">def</span> <span class="token function">read_uq_arr</span><span class="token punctuation">(</span>dataset_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> gene_num<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Array<span class="token punctuation">:</span>
    cols_to_keep <span class="token operator">=</span> choose_common_gene<span class="token punctuation">(</span>gene_num<span class="token punctuation">)</span>
    BC32_gex <span class="token operator">=</span> sc<span class="token punctuation">.</span>read_h5ad<span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC32/BC32_gex.h5ad&quot;</span><span class="token punctuation">)</span>
    BC32_uq1729_df <span class="token operator">=</span> BC32_gex<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> BC32_gex<span class="token punctuation">.</span>var<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>cols_to_keep<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_df<span class="token punctuation">(</span><span class="token punctuation">)</span>
    BC32_uq1729_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>BC32_uq1729_df<span class="token punctuation">)</span>
    BC32_uq1729 <span class="token operator">=</span> get_normed_array<span class="token punctuation">(</span>BC32_uq1729_arr<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC32&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> BC32_uq1729
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC15&#39;</span><span class="token punctuation">:</span>
        BC11_gex <span class="token operator">=</span> sc<span class="token punctuation">.</span>read_h5ad<span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/BC15_gex.h5ad&quot;</span><span class="token punctuation">)</span>
        BC11_uq_x_df <span class="token operator">=</span> BC11_gex<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                                BC11_gex<span class="token punctuation">.</span>var<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>cols_to_keep<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_df<span class="token punctuation">(</span><span class="token punctuation">)</span>
        BC11_uq1729_df <span class="token operator">=</span> BC11_uq_x_df<span class="token punctuation">.</span>reindex<span class="token punctuation">(</span>columns<span class="token operator">=</span>BC32_uq1729_df<span class="token punctuation">.</span>columns<span class="token punctuation">,</span>
                                              fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        BC11_uq1729_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>BC11_uq1729_df<span class="token punctuation">)</span>
        BC11_uq1729 <span class="token operator">=</span> get_normed_array<span class="token punctuation">(</span>BC11_uq1729_arr<span class="token punctuation">)</span>
        <span class="token keyword">return</span> BC11_uq1729

    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC11&#39;</span><span class="token punctuation">:</span>
        BC11_gex <span class="token operator">=</span> sc<span class="token punctuation">.</span>read_h5ad<span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/BC11/BC11_gex.h5ad&quot;</span><span class="token punctuation">)</span>
        BC11_uq_x_df <span class="token operator">=</span> BC11_gex<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                                BC11_gex<span class="token punctuation">.</span>var<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>cols_to_keep<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_df<span class="token punctuation">(</span><span class="token punctuation">)</span>
        BC11_uq1729_df <span class="token operator">=</span> BC11_uq_x_df<span class="token punctuation">.</span>reindex<span class="token punctuation">(</span>columns<span class="token operator">=</span>BC32_uq1729_df<span class="token punctuation">.</span>columns<span class="token punctuation">,</span>
                                              fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        BC11_uq1729_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>BC11_uq1729_df<span class="token punctuation">)</span>
        BC11_uq1729 <span class="token operator">=</span> get_normed_array<span class="token punctuation">(</span>BC11_uq1729_arr<span class="token punctuation">)</span>
        <span class="token keyword">return</span> BC11_uq1729


<span class="token comment"># 读取数据标签</span>
<span class="token keyword">def</span> <span class="token function">read_label</span><span class="token punctuation">(</span>dataset_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC32&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC32/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            labels <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC15&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            labels <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC11&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/BC11/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            labels <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    labels<span class="token punctuation">,</span> classes <span class="token operator">=</span> pd<span class="token punctuation">.</span>factorize<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    <span class="token keyword">return</span> labels<span class="token punctuation">,</span> classes


<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC32/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>

    BC32_labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>

    BC32_labels<span class="token punctuation">,</span> BC32_classes <span class="token operator">=</span> pd<span class="token punctuation">.</span>factorize<span class="token punctuation">(</span>BC32_labels<span class="token punctuation">)</span>



<span class="token keyword">class</span> <span class="token class-name">myDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details></details><h2 id="_4-根据编码器进行预测" tabindex="-1"><a class="header-anchor" href="#_4-根据编码器进行预测" aria-hidden="true">#</a> 4 根据编码器进行预测</h2><ul><li>继承</li><li>添加层</li><li>初始化权重</li><li></li></ul><details class="hint-container details"><summary>Details</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;ae.py&#39;</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> TypeVar
<span class="token keyword">from</span> model<span class="token punctuation">.</span>base_ae <span class="token keyword">import</span> BaseAE

Tensor <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&#39;torch.tensor&#39;</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">AE</span><span class="token punctuation">(</span>BaseAE<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>  <span class="token comment"># AE的构造函数</span>
                 input_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 latent_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 hidden_dims<span class="token punctuation">:</span> List <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
                 dop<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
                 noise_flag<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>latent_dim <span class="token operator">=</span> latent_dim
        self<span class="token punctuation">.</span>noise_flag <span class="token operator">=</span> noise_flag
        self<span class="token punctuation">.</span>dop <span class="token operator">=</span> dop

        <span class="token keyword">if</span> hidden_dims <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span>

        <span class="token comment"># build encoder</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 添加第一个隐藏层</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 循环添加中间隐藏层</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 添加最后一个隐藏层，输出维度为latent_dim</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 将以上层组成encoder</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        <span class="token comment"># build decoder(同encoder)</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        hidden_dims2 <span class="token operator">=</span> hidden_dims<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 确保encoder和decoder层对称</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>final_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 调用初始化权重方法</span>
        initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 编码输出隐藏层结果</span>
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>noise_flag <span class="token keyword">and</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span> <span class="token comment"># 判断噪音tag/训练模式-&gt;是否添加噪音</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>
                <span class="token builtin">input</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">)</span> <span class="token comment"># 隐藏层的位置添加0.05的噪音</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> latent_code

    <span class="token comment"># 解码输出最终结果</span>
    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>final_layer<span class="token punctuation">(</span>embed<span class="token punctuation">)</span>

        <span class="token keyword">return</span> outputs

    <span class="token comment"># 前向传播，返回三个参数[输入值，隐藏值，重构值]</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">,</span> z<span class="token punctuation">]</span>

    <span class="token comment"># 定义损失函数(MSE(均方误差))</span>
    <span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        recons <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        recons_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> recons<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> recons_loss

        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">&#39;recons_loss&#39;</span><span class="token punctuation">:</span> recons_loss<span class="token punctuation">}</span>

    <span class="token comment"># 定义采样的函数（在隐藏层随机采样）</span>
    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_samples<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> current_device<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
               <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_samples<span class="token punctuation">,</span> self<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span>

        z <span class="token operator">=</span> z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>current_device<span class="token punctuation">)</span>
        samples <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

        <span class="token keyword">return</span> samples

    
    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Initialize weights using Xavier initialization</span>
    <span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">细节补充</p></div></details>`,16),o=[e];function c(i,l){return s(),a("div",null,o)}const k=n(t,[["render",c],["__file","从头开始写一个MLP模型.html.vue"]]);export{k as default};
