const e=JSON.parse(`{"key":"v-a8937570","path":"/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/KL%20Diversion%20%EF%BC%86%20JS%20Diversion.html","title":"KL Diversion ＆ JS Diversion","lang":"en-US","frontmatter":{"title":"KL Diversion ＆ JS Diversion","date":"2023-03-05T00:00:00.000Z","tag":["Deep Learning","Diversion"],"category":["深度学习","分布差异"],"description":"KL Diversion ＆ JS Diversion 简介 KL散度和JS散度本质上都是用于用来衡量两个分布之间的差异的值，并且分别具有一些不一样的性质，并且通常它们分别对应用于解决一些不一样的实际问题。 这篇文章从信息论和熵为起点，展开对 KL Diversion 和 JS Diversion 的介绍。","head":[["link",{"rel":"alternate","hreflang":"zh-cn","href":"https://Huahuatii.github.io/zh/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/KL%20Diversion%20%EF%BC%86%20JS%20Diversion.html"}],["meta",{"property":"og:url","content":"https://Huahuatii.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/KL%20Diversion%20%EF%BC%86%20JS%20Diversion.html"}],["meta",{"property":"og:site_name","content":"Huahuatii's Blog"}],["meta",{"property":"og:title","content":"KL Diversion ＆ JS Diversion"}],["meta",{"property":"og:description","content":"KL Diversion ＆ JS Diversion 简介 KL散度和JS散度本质上都是用于用来衡量两个分布之间的差异的值，并且分别具有一些不一样的性质，并且通常它们分别对应用于解决一些不一样的实际问题。 这篇文章从信息论和熵为起点，展开对 KL Diversion 和 JS Diversion 的介绍。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://Huahuatii.github.io/"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:locale:alternate","content":"zh-CN"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"KL Diversion ＆ JS Diversion"}],["meta",{"property":"article:tag","content":"Deep Learning"}],["meta",{"property":"article:tag","content":"Diversion"}],["meta",{"property":"article:published_time","content":"2023-03-05T00:00:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"KL Diversion ＆ JS Diversion\\",\\"image\\":[\\"https://Huahuatii.github.io/\\"],\\"datePublished\\":\\"2023-03-05T00:00:00.000Z\\",\\"dateModified\\":null,\\"author\\":[]}"]]},"headers":[{"level":2,"title":"1 信息论","slug":"_1-信息论","link":"#_1-信息论","children":[]},{"level":2,"title":"2 熵","slug":"_2-熵","link":"#_2-熵","children":[]},{"level":2,"title":"3 Divsersion","slug":"_3-divsersion","link":"#_3-divsersion","children":[{"level":3,"title":"3.1 KL Diversion（相对熵）","slug":"_3-1-kl-diversion-相对熵","link":"#_3-1-kl-diversion-相对熵","children":[]},{"level":3,"title":"3.2 Cross Entropy（交叉熵）","slug":"_3-2-cross-entropy-交叉熵","link":"#_3-2-cross-entropy-交叉熵","children":[]},{"level":3,"title":"3.3 JS Diversion","slug":"_3-3-js-diversion","link":"#_3-3-js-diversion","children":[]},{"level":3,"title":"3.4 Wasserstein距离","slug":"_3-4-wasserstein距离","link":"#_3-4-wasserstein距离","children":[]}]},{"level":2,"title":"4 参考资料","slug":"_4-参考资料","link":"#_4-参考资料","children":[]},{"level":2,"title":"5 VAE-Model示意图","slug":"_5-vae-model示意图","link":"#_5-vae-model示意图","children":[]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":3.54,"words":1063},"filePathRelative":"posts/深度学习/KL Diversion ＆ JS Diversion.md","localizedDate":"March 5, 2023","excerpt":"<h1> KL Diversion ＆ JS Diversion</h1>\\n<div class=\\"hint-container tip\\">\\n<p class=\\"hint-container-title\\">简介</p>\\n<p>KL散度和JS散度本质上都是用于用来衡量两个分布之间的差异的值，并且分别具有一些不一样的性质，并且通常它们分别对应用于解决一些不一样的实际问题。</p>\\n<p>这篇文章从<strong>信息论</strong>和<strong>熵</strong>为起点，展开对 <mark><strong>KL Diversion</strong></mark> 和 <mark><strong>JS Diversion</strong></mark> 的介绍。</p>\\n</div>","autoDesc":true}`);export{e as data};
