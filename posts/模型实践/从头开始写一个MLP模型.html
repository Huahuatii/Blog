<!DOCTYPE html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.60" />
    <meta name="theme" content="VuePress Theme Hope" />
    <link rel="alternate" hreflang="zh-cn" href="https://Huahuatii.github.io/zh/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html"><meta property="og:url" content="https://Huahuatii.github.io/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html"><meta property="og:site_name" content="Huahuatii's Blog"><meta property="og:title" content="从0开始搭建Auto-Encoder"><meta property="og:description" content="从0开始搭建Auto-Encoder 搭建Auto-Encoder模型的时候，选择了更加结构化的搭建模式： 搭建base_ae：这一步用来确定一个ae模型的基本结构会有哪些（其中有部分未必会用到） 1 搭建base_AE模型 初始化 编码函数 解码函数 采样函数 生成函数 前向传播（抽象方法） 损失函数（抽象方法） 'base_ae.py' from torch import nn from abc import abstractmethod # 定义抽象方法 from typing import TypeVar # 定义数据类新的接口 from typing import List, Any Tensor = TypeVar('torch.tensor') # 定义泛型变量，表示一个 PyTorch 的 tensor class BaseAE(nn.Module): def __init__(self) -&gt; None: # 初始化神经网络模型的各个组件 super(BaseAE, self).__init__() def encode(self, input: Tensor) -&gt; List[Tensor]: # 定义一个编码过程 raise NotImplementedError def decode(self, input: Tensor) -&gt; List[Tensor]: # 定义一个解码过程 raise NotImplementedError def sample(self, batch_size: int, current_device: int, **kwargs) -&gt; Tensor: # 定义一个采样方法 raise RuntimeWarning() def generate(self, x: Tensor, **kwargs) -&gt; Tensor: # 定义一个生成方法 raise NotImplementedError def initialize_weights(self) -&gt; None: # 定义初始化权重方法 raise NotImplementedError @abstractmethod # 装饰器，声明下面的方法为抽象方法 def forward(self, *inputs: Tensor) -&gt; Tensor: # 定义前向传播过程 pass @abstractmethod def loss_function(self, *inputs: Any, **kwargs) -&gt; Tensor: # 定义损失函数 pass"><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:locale:alternate" content="zh-CN"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="Model Practice"><meta property="article:tag" content="MLP"><meta property="article:published_time" content="2023-03-18T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"从0开始搭建Auto-Encoder","image":[""],"datePublished":"2023-03-18T00:00:00.000Z","dateModified":null,"author":[]}</script><title>从0开始搭建Auto-Encoder | Huahuatii's Blog</title><meta name="description" content="从0开始搭建Auto-Encoder 搭建Auto-Encoder模型的时候，选择了更加结构化的搭建模式： 搭建base_ae：这一步用来确定一个ae模型的基本结构会有哪些（其中有部分未必会用到） 1 搭建base_AE模型 初始化 编码函数 解码函数 采样函数 生成函数 前向传播（抽象方法） 损失函数（抽象方法） 'base_ae.py' from torch import nn from abc import abstractmethod # 定义抽象方法 from typing import TypeVar # 定义数据类新的接口 from typing import List, Any Tensor = TypeVar('torch.tensor') # 定义泛型变量，表示一个 PyTorch 的 tensor class BaseAE(nn.Module): def __init__(self) -&gt; None: # 初始化神经网络模型的各个组件 super(BaseAE, self).__init__() def encode(self, input: Tensor) -&gt; List[Tensor]: # 定义一个编码过程 raise NotImplementedError def decode(self, input: Tensor) -&gt; List[Tensor]: # 定义一个解码过程 raise NotImplementedError def sample(self, batch_size: int, current_device: int, **kwargs) -&gt; Tensor: # 定义一个采样方法 raise RuntimeWarning() def generate(self, x: Tensor, **kwargs) -&gt; Tensor: # 定义一个生成方法 raise NotImplementedError def initialize_weights(self) -&gt; None: # 定义初始化权重方法 raise NotImplementedError @abstractmethod # 装饰器，声明下面的方法为抽象方法 def forward(self, *inputs: Tensor) -&gt; Tensor: # 定义前向传播过程 pass @abstractmethod def loss_function(self, *inputs: Any, **kwargs) -&gt; Tensor: # 定义损失函数 pass">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-e6ba4ee4.css" as="style"><link rel="stylesheet" href="/assets/style-e6ba4ee4.css">
    <link rel="modulepreload" href="/assets/app-372f1543.js"><link rel="modulepreload" href="/assets/framework-179f767b.js"><link rel="modulepreload" href="/assets/从头开始写一个MLP模型.html-febe221d.js"><link rel="modulepreload" href="/assets/从头开始写一个MLP模型.html-06b1beed.js"><link rel="prefetch" href="/assets/intro.html-8f31f2ad.js" as="script"><link rel="prefetch" href="/assets/index.html-fad62e17.js" as="script"><link rel="prefetch" href="/assets/slides.html-a1d2f05a.js" as="script"><link rel="prefetch" href="/assets/disable.html-df7a39f0.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-75fd784b.js" as="script"><link rel="prefetch" href="/assets/markdown.html-9659e74b.js" as="script"><link rel="prefetch" href="/assets/page.html-ea0f5529.js" as="script"><link rel="prefetch" href="/assets/index.html-2000d3bd.js" as="script"><link rel="prefetch" href="/assets/intro.html-59b58e7d.js" as="script"><link rel="prefetch" href="/assets/index.html-b92a6ff6.js" as="script"><link rel="prefetch" href="/assets/slides.html-a72cc154.js" as="script"><link rel="prefetch" href="/assets/Argparse模块.html-dd0a6115.js" as="script"><link rel="prefetch" href="/assets/Numpy＆Pandas.html-af2d00a1.js" as="script"><link rel="prefetch" href="/assets/每天一个python小技巧.html-dfe92292.js" as="script"><link rel="prefetch" href="/assets/CODE-AE.html-75878550.js" as="script"><link rel="prefetch" href="/assets/SAN.html-e01dee79.js" as="script"><link rel="prefetch" href="/assets/SAN__.html-2a39ca0c.js" as="script"><link rel="prefetch" href="/assets/scDEAL.html-2c234f51.js" as="script"><link rel="prefetch" href="/assets/模板.html-eb7fe834.js" as="script"><link rel="prefetch" href="/assets/Attention.html-2c09feea.js" as="script"><link rel="prefetch" href="/assets/KL Diversion ＆ JS Diversion.html-af76fe58.js" as="script"><link rel="prefetch" href="/assets/Loss Function.html-793395cd.js" as="script"><link rel="prefetch" href="/assets/Tensorboard.html-94b7c011.js" as="script"><link rel="prefetch" href="/assets/最大均值差异（Maximum Mean Discrepancy，MMD）.html-87511faf.js" as="script"><link rel="prefetch" href="/assets/范数.html-2981f398.js" as="script"><link rel="prefetch" href="/assets/VuePress_reco.html-5ce64bf7.js" as="script"><link rel="prefetch" href="/assets/disable.html-f6997549.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-e32b6465.js" as="script"><link rel="prefetch" href="/assets/markdown.html-35fa3ed9.js" as="script"><link rel="prefetch" href="/assets/page.html-dcc245f2.js" as="script"><link rel="prefetch" href="/assets/index.html-6f40111f.js" as="script"><link rel="prefetch" href="/assets/Argparse模块.html-d76cf68d.js" as="script"><link rel="prefetch" href="/assets/Numpy＆Pandas.html-8f620004.js" as="script"><link rel="prefetch" href="/assets/每天一个python小技巧.html-ba73e865.js" as="script"><link rel="prefetch" href="/assets/CODE-AE.html-eefc8948.js" as="script"><link rel="prefetch" href="/assets/SAN.html-6c2cb1a1.js" as="script"><link rel="prefetch" href="/assets/SAN__.html-89ecc83a.js" as="script"><link rel="prefetch" href="/assets/scDEAL.html-0069e12c.js" as="script"><link rel="prefetch" href="/assets/模板.html-61e97dd0.js" as="script"><link rel="prefetch" href="/assets/从头开始写一个MLP模型.html-3b5126d1.js" as="script"><link rel="prefetch" href="/assets/Attention.html-c79c1255.js" as="script"><link rel="prefetch" href="/assets/KL Diversion ＆ JS Diversion.html-c80e029a.js" as="script"><link rel="prefetch" href="/assets/Loss Function.html-bf3fc09f.js" as="script"><link rel="prefetch" href="/assets/Tensorboard.html-66530383.js" as="script"><link rel="prefetch" href="/assets/最大均值差异（Maximum Mean Discrepancy，MMD）.html-7457835c.js" as="script"><link rel="prefetch" href="/assets/范数.html-721fb765.js" as="script"><link rel="prefetch" href="/assets/VuePress_reco.html-ab053b11.js" as="script"><link rel="prefetch" href="/assets/404.html-543363b7.js" as="script"><link rel="prefetch" href="/assets/index.html-e79207b3.js" as="script"><link rel="prefetch" href="/assets/index.html-c2629f6a.js" as="script"><link rel="prefetch" href="/assets/index.html-d0fdcef4.js" as="script"><link rel="prefetch" href="/assets/index.html-2cb6a144.js" as="script"><link rel="prefetch" href="/assets/index.html-8f00acde.js" as="script"><link rel="prefetch" href="/assets/index.html-61abad02.js" as="script"><link rel="prefetch" href="/assets/index.html-c3a93a2d.js" as="script"><link rel="prefetch" href="/assets/index.html-f66ffe7d.js" as="script"><link rel="prefetch" href="/assets/index.html-de186d41.js" as="script"><link rel="prefetch" href="/assets/index.html-322a8afa.js" as="script"><link rel="prefetch" href="/assets/index.html-8c42a8bc.js" as="script"><link rel="prefetch" href="/assets/index.html-8494f41b.js" as="script"><link rel="prefetch" href="/assets/index.html-0394c26d.js" as="script"><link rel="prefetch" href="/assets/index.html-b4955161.js" as="script"><link rel="prefetch" href="/assets/index.html-f63d4315.js" as="script"><link rel="prefetch" href="/assets/index.html-8e90bbe3.js" as="script"><link rel="prefetch" href="/assets/index.html-473df391.js" as="script"><link rel="prefetch" href="/assets/index.html-ebc03a63.js" as="script"><link rel="prefetch" href="/assets/index.html-9d01d1a3.js" as="script"><link rel="prefetch" href="/assets/index.html-83f07054.js" as="script"><link rel="prefetch" href="/assets/index.html-c784a201.js" as="script"><link rel="prefetch" href="/assets/index.html-8123d67d.js" as="script"><link rel="prefetch" href="/assets/index.html-6a253dfb.js" as="script"><link rel="prefetch" href="/assets/index.html-6f305aca.js" as="script"><link rel="prefetch" href="/assets/index.html-06c2c1bd.js" as="script"><link rel="prefetch" href="/assets/index.html-58a84755.js" as="script"><link rel="prefetch" href="/assets/index.html-f14e06f2.js" as="script"><link rel="prefetch" href="/assets/index.html-e694ade7.js" as="script"><link rel="prefetch" href="/assets/index.html-da32eb91.js" as="script"><link rel="prefetch" href="/assets/index.html-4c37483f.js" as="script"><link rel="prefetch" href="/assets/index.html-954f60d0.js" as="script"><link rel="prefetch" href="/assets/index.html-a92d0735.js" as="script"><link rel="prefetch" href="/assets/index.html-5d010674.js" as="script"><link rel="prefetch" href="/assets/index.html-c95c38a8.js" as="script"><link rel="prefetch" href="/assets/index.html-d650a9e5.js" as="script"><link rel="prefetch" href="/assets/index.html-09a51171.js" as="script"><link rel="prefetch" href="/assets/index.html-145671e8.js" as="script"><link rel="prefetch" href="/assets/index.html-7cbeb870.js" as="script"><link rel="prefetch" href="/assets/index.html-0ccea42f.js" as="script"><link rel="prefetch" href="/assets/index.html-5ea97e0c.js" as="script"><link rel="prefetch" href="/assets/index.html-90c698c0.js" as="script"><link rel="prefetch" href="/assets/index.html-03caa38a.js" as="script"><link rel="prefetch" href="/assets/index.html-ef926e89.js" as="script"><link rel="prefetch" href="/assets/index.html-03f5a504.js" as="script"><link rel="prefetch" href="/assets/index.html-b7da7c10.js" as="script"><link rel="prefetch" href="/assets/index.html-80124674.js" as="script"><link rel="prefetch" href="/assets/index.html-cf709760.js" as="script"><link rel="prefetch" href="/assets/index.html-ab69b840.js" as="script"><link rel="prefetch" href="/assets/index.html-bf6ff749.js" as="script"><link rel="prefetch" href="/assets/index.html-e3ad7f0a.js" as="script"><link rel="prefetch" href="/assets/index.html-6dd68afc.js" as="script"><link rel="prefetch" href="/assets/index.html-56f37716.js" as="script"><link rel="prefetch" href="/assets/index.html-12f9fbcb.js" as="script"><link rel="prefetch" href="/assets/index.html-cf54eece.js" as="script"><link rel="prefetch" href="/assets/index.html-1985a792.js" as="script"><link rel="prefetch" href="/assets/index.html-b94a40a8.js" as="script"><link rel="prefetch" href="/assets/index.html-a419435d.js" as="script"><link rel="prefetch" href="/assets/index.html-4e6e3668.js" as="script"><link rel="prefetch" href="/assets/index.html-05cc1621.js" as="script"><link rel="prefetch" href="/assets/index.html-f645747c.js" as="script"><link rel="prefetch" href="/assets/index.html-64d0019b.js" as="script"><link rel="prefetch" href="/assets/index.html-a4f03e0d.js" as="script"><link rel="prefetch" href="/assets/index.html-4a8d222f.js" as="script"><link rel="prefetch" href="/assets/index.html-52f4f700.js" as="script"><link rel="prefetch" href="/assets/index.html-a1c85659.js" as="script"><link rel="prefetch" href="/assets/index.html-d21e1546.js" as="script"><link rel="prefetch" href="/assets/index.html-88eb8c54.js" as="script"><link rel="prefetch" href="/assets/index.html-0d519d84.js" as="script"><link rel="prefetch" href="/assets/index.html-010674d2.js" as="script"><link rel="prefetch" href="/assets/index.html-2ce99e52.js" as="script"><link rel="prefetch" href="/assets/index.html-dee5f9b8.js" as="script"><link rel="prefetch" href="/assets/index.html-c883d860.js" as="script"><link rel="prefetch" href="/assets/index.html-f7708747.js" as="script"><link rel="prefetch" href="/assets/index.html-5d4c96d6.js" as="script"><link rel="prefetch" href="/assets/index.html-cf160194.js" as="script"><link rel="prefetch" href="/assets/index.html-1a71b5a7.js" as="script"><link rel="prefetch" href="/assets/index.html-160b9236.js" as="script"><link rel="prefetch" href="/assets/index.html-b5782978.js" as="script"><link rel="prefetch" href="/assets/index.html-156d00fb.js" as="script"><link rel="prefetch" href="/assets/index.html-4f6fa3c2.js" as="script"><link rel="prefetch" href="/assets/index.html-5301df73.js" as="script"><link rel="prefetch" href="/assets/index.html-a6c76fc8.js" as="script"><link rel="prefetch" href="/assets/intro.html-6bba7a0d.js" as="script"><link rel="prefetch" href="/assets/index.html-ed7705f2.js" as="script"><link rel="prefetch" href="/assets/slides.html-f8ba2255.js" as="script"><link rel="prefetch" href="/assets/disable.html-e4b7d817.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-32e184bc.js" as="script"><link rel="prefetch" href="/assets/markdown.html-6975f699.js" as="script"><link rel="prefetch" href="/assets/page.html-bc04b1b9.js" as="script"><link rel="prefetch" href="/assets/index.html-c92167b2.js" as="script"><link rel="prefetch" href="/assets/intro.html-543b8bd3.js" as="script"><link rel="prefetch" href="/assets/index.html-09217afe.js" as="script"><link rel="prefetch" href="/assets/slides.html-238f126e.js" as="script"><link rel="prefetch" href="/assets/Argparse模块.html-f79ac3c3.js" as="script"><link rel="prefetch" href="/assets/Numpy＆Pandas.html-68d9bc80.js" as="script"><link rel="prefetch" href="/assets/每天一个python小技巧.html-41b7d47e.js" as="script"><link rel="prefetch" href="/assets/CODE-AE.html-913db8d8.js" as="script"><link rel="prefetch" href="/assets/SAN.html-b4d7b09d.js" as="script"><link rel="prefetch" href="/assets/SAN__.html-bc7dce4a.js" as="script"><link rel="prefetch" href="/assets/scDEAL.html-4213f9ef.js" as="script"><link rel="prefetch" href="/assets/模板.html-6f3d799c.js" as="script"><link rel="prefetch" href="/assets/Attention.html-e834091c.js" as="script"><link rel="prefetch" href="/assets/KL Diversion ＆ JS Diversion.html-dc0efd1a.js" as="script"><link rel="prefetch" href="/assets/Loss Function.html-f4471945.js" as="script"><link rel="prefetch" href="/assets/Tensorboard.html-d5d75981.js" as="script"><link rel="prefetch" href="/assets/最大均值差异（Maximum Mean Discrepancy，MMD）.html-540d0145.js" as="script"><link rel="prefetch" href="/assets/范数.html-bbd58360.js" as="script"><link rel="prefetch" href="/assets/VuePress_reco.html-9fd63978.js" as="script"><link rel="prefetch" href="/assets/disable.html-66b3eba1.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-694146ed.js" as="script"><link rel="prefetch" href="/assets/markdown.html-47f2fcc6.js" as="script"><link rel="prefetch" href="/assets/page.html-cf34d7dc.js" as="script"><link rel="prefetch" href="/assets/index.html-98225b81.js" as="script"><link rel="prefetch" href="/assets/Argparse模块.html-627867b3.js" as="script"><link rel="prefetch" href="/assets/Numpy＆Pandas.html-94ffa18d.js" as="script"><link rel="prefetch" href="/assets/每天一个python小技巧.html-6568b2dd.js" as="script"><link rel="prefetch" href="/assets/CODE-AE.html-0e9cfd84.js" as="script"><link rel="prefetch" href="/assets/SAN.html-82fcb705.js" as="script"><link rel="prefetch" href="/assets/SAN__.html-26a85514.js" as="script"><link rel="prefetch" href="/assets/scDEAL.html-06495eac.js" as="script"><link rel="prefetch" href="/assets/模板.html-ec622b2a.js" as="script"><link rel="prefetch" href="/assets/从头开始写一个MLP模型.html-b730a521.js" as="script"><link rel="prefetch" href="/assets/Attention.html-16046721.js" as="script"><link rel="prefetch" href="/assets/KL Diversion ＆ JS Diversion.html-843e6591.js" as="script"><link rel="prefetch" href="/assets/Loss Function.html-38e1dcce.js" as="script"><link rel="prefetch" href="/assets/Tensorboard.html-953f3d38.js" as="script"><link rel="prefetch" href="/assets/最大均值差异（Maximum Mean Discrepancy，MMD）.html-b95128d0.js" as="script"><link rel="prefetch" href="/assets/范数.html-a15c633f.js" as="script"><link rel="prefetch" href="/assets/VuePress_reco.html-253eeee3.js" as="script"><link rel="prefetch" href="/assets/404.html-300e0f6d.js" as="script"><link rel="prefetch" href="/assets/index.html-11cc5000.js" as="script"><link rel="prefetch" href="/assets/index.html-0071e233.js" as="script"><link rel="prefetch" href="/assets/index.html-a2d43b01.js" as="script"><link rel="prefetch" href="/assets/index.html-59cba41c.js" as="script"><link rel="prefetch" href="/assets/index.html-44814a32.js" as="script"><link rel="prefetch" href="/assets/index.html-e6716668.js" as="script"><link rel="prefetch" href="/assets/index.html-1769de8f.js" as="script"><link rel="prefetch" href="/assets/index.html-9ce74dec.js" as="script"><link rel="prefetch" href="/assets/index.html-fbf59eff.js" as="script"><link rel="prefetch" href="/assets/index.html-6f36a94f.js" as="script"><link rel="prefetch" href="/assets/index.html-d3533bc2.js" as="script"><link rel="prefetch" href="/assets/index.html-5cdf0c8b.js" as="script"><link rel="prefetch" href="/assets/index.html-b2cfe8b4.js" as="script"><link rel="prefetch" href="/assets/index.html-5270ad3a.js" as="script"><link rel="prefetch" href="/assets/index.html-56acc573.js" as="script"><link rel="prefetch" href="/assets/index.html-3e07fe4a.js" as="script"><link rel="prefetch" href="/assets/index.html-d601fb50.js" as="script"><link rel="prefetch" href="/assets/index.html-9c7a842c.js" as="script"><link rel="prefetch" href="/assets/index.html-2f3d1197.js" as="script"><link rel="prefetch" href="/assets/index.html-8c569350.js" as="script"><link rel="prefetch" href="/assets/index.html-d1ae32c3.js" as="script"><link rel="prefetch" href="/assets/index.html-f6c63999.js" as="script"><link rel="prefetch" href="/assets/index.html-07f00af9.js" as="script"><link rel="prefetch" href="/assets/index.html-b8132ec5.js" as="script"><link rel="prefetch" href="/assets/index.html-ac073c61.js" as="script"><link rel="prefetch" href="/assets/index.html-87dff539.js" as="script"><link rel="prefetch" href="/assets/index.html-fde803a8.js" as="script"><link rel="prefetch" href="/assets/index.html-d52b9263.js" as="script"><link rel="prefetch" href="/assets/index.html-657570aa.js" as="script"><link rel="prefetch" href="/assets/index.html-72bad10a.js" as="script"><link rel="prefetch" href="/assets/index.html-62162e53.js" as="script"><link rel="prefetch" href="/assets/index.html-e57da28e.js" as="script"><link rel="prefetch" href="/assets/index.html-1572018b.js" as="script"><link rel="prefetch" href="/assets/index.html-3845e791.js" as="script"><link rel="prefetch" href="/assets/index.html-bcf1bbe0.js" as="script"><link rel="prefetch" href="/assets/index.html-0b979c41.js" as="script"><link rel="prefetch" href="/assets/index.html-b362f760.js" as="script"><link rel="prefetch" href="/assets/index.html-abfeb45d.js" as="script"><link rel="prefetch" href="/assets/index.html-9324768e.js" as="script"><link rel="prefetch" href="/assets/index.html-527b1db5.js" as="script"><link rel="prefetch" href="/assets/index.html-bbf045ab.js" as="script"><link rel="prefetch" href="/assets/index.html-4f3a182d.js" as="script"><link rel="prefetch" href="/assets/index.html-87f167d1.js" as="script"><link rel="prefetch" href="/assets/index.html-bf404df7.js" as="script"><link rel="prefetch" href="/assets/index.html-e4254d5b.js" as="script"><link rel="prefetch" href="/assets/index.html-3cc74f4a.js" as="script"><link rel="prefetch" href="/assets/index.html-e9f6d789.js" as="script"><link rel="prefetch" href="/assets/index.html-b924141e.js" as="script"><link rel="prefetch" href="/assets/index.html-8a7410a3.js" as="script"><link rel="prefetch" href="/assets/index.html-77a433c7.js" as="script"><link rel="prefetch" href="/assets/index.html-2ebaab0e.js" as="script"><link rel="prefetch" href="/assets/index.html-9167d8d0.js" as="script"><link rel="prefetch" href="/assets/index.html-211b8248.js" as="script"><link rel="prefetch" href="/assets/index.html-2bffddd2.js" as="script"><link rel="prefetch" href="/assets/index.html-04a9a90a.js" as="script"><link rel="prefetch" href="/assets/index.html-1582ce94.js" as="script"><link rel="prefetch" href="/assets/index.html-47d49782.js" as="script"><link rel="prefetch" href="/assets/index.html-3ed08f28.js" as="script"><link rel="prefetch" href="/assets/index.html-1723a1fa.js" as="script"><link rel="prefetch" href="/assets/index.html-fb721776.js" as="script"><link rel="prefetch" href="/assets/index.html-393d37fb.js" as="script"><link rel="prefetch" href="/assets/index.html-09e747d3.js" as="script"><link rel="prefetch" href="/assets/index.html-7e8562ff.js" as="script"><link rel="prefetch" href="/assets/index.html-9ea6a19e.js" as="script"><link rel="prefetch" href="/assets/index.html-a416f70d.js" as="script"><link rel="prefetch" href="/assets/index.html-65da6c16.js" as="script"><link rel="prefetch" href="/assets/index.html-9df9e805.js" as="script"><link rel="prefetch" href="/assets/index.html-3433e8ca.js" as="script"><link rel="prefetch" href="/assets/index.html-f0328645.js" as="script"><link rel="prefetch" href="/assets/index.html-8a0a6a19.js" as="script"><link rel="prefetch" href="/assets/index.html-bf066c63.js" as="script"><link rel="prefetch" href="/assets/index.html-f0622f31.js" as="script"><link rel="prefetch" href="/assets/index.html-9b02d484.js" as="script"><link rel="prefetch" href="/assets/index.html-bf3cc264.js" as="script"><link rel="prefetch" href="/assets/index.html-cdf8c696.js" as="script"><link rel="prefetch" href="/assets/index.html-81923adc.js" as="script"><link rel="prefetch" href="/assets/index.html-9d98cb35.js" as="script"><link rel="prefetch" href="/assets/index.html-45e98042.js" as="script"><link rel="prefetch" href="/assets/index.html-4eb187e7.js" as="script"><link rel="prefetch" href="/assets/index.html-8f7bca98.js" as="script"><link rel="prefetch" href="/assets/index.html-dbee553b.js" as="script"><link rel="prefetch" href="/assets/index.html-bb9b9cf2.js" as="script"><link rel="prefetch" href="/assets/giscus-6650c2d9.js" as="script"><link rel="prefetch" href="/assets/auto-ba5ecab5.js" as="script"><link rel="prefetch" href="/assets/index-8764208e.js" as="script"><link rel="prefetch" href="/assets/flowchart-35969cab.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-618f3525.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-a794bb63.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-d92a2fc9.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-224f94d9.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-e5069ce0.js" as="script"><link rel="prefetch" href="/assets/search.esm-2c3fba7d.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-dd955d4b.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-6e6cbe40.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container has-toc"><!--[--><header class="navbar" id="navbar"><div class="navbar-start"><button class="toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><a href="/" class="brand"><img class="logo" src="/HTT.jpg" alt="Huahuatii&#39;s Blog"><!----><span class="site-name hide-in-pad">Huahuatii&#39;s Blog</span></a><!--[--><!----><!--]--></div><div class="navbar-center"><!--[--><!----><!--]--><nav class="nav-links"><div class="nav-item hide-in-mobile"><a href="/" class="nav-link" aria-label="Blog Home"><span class="font-icon icon iconfont icon-home" style=""></span>Blog Home<!----></a></div><div class="nav-item hide-in-mobile"><a href="/demo/" class="nav-link" aria-label="Demo"><span class="font-icon icon iconfont icon-discover" style=""></span>Demo<!----></a></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button class="dropdown-title" type="button" aria-label="Posts"><span class="title"><span class="font-icon icon iconfont icon-edit" style=""></span>Posts</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>Apple</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/posts/apple/1" class="nav-link" aria-label="Apple1"><span class="font-icon icon iconfont icon-edit" style=""></span>Apple1<!----></a></li><li class="dropdown-subitem"><a href="/posts/apple/2" class="nav-link" aria-label="Apple2"><span class="font-icon icon iconfont icon-edit" style=""></span>Apple2<!----></a></li><li class="dropdown-subitem"><a href="/posts/apple/3" class="nav-link" aria-label="/posts/apple/3"><!---->/posts/apple/3<!----></a></li><li class="dropdown-subitem"><a href="/posts/apple/4" class="nav-link" aria-label="/posts/apple/4"><!---->/posts/apple/4<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>Banana</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/posts/banana/1" class="nav-link" aria-label="Banana 1"><span class="font-icon icon iconfont icon-edit" style=""></span>Banana 1<!----></a></li><li class="dropdown-subitem"><a href="/posts/banana/2" class="nav-link" aria-label="Banana 2"><span class="font-icon icon iconfont icon-edit" style=""></span>Banana 2<!----></a></li><li class="dropdown-subitem"><a href="/posts/banana/3" class="nav-link" aria-label="/posts/banana/3"><!---->/posts/banana/3<!----></a></li><li class="dropdown-subitem"><a href="/posts/banana/4" class="nav-link" aria-label="/posts/banana/4"><!---->/posts/banana/4<!----></a></li></ul></li><li class="dropdown-item"><a href="/posts/cherry" class="nav-link" aria-label="Cherry"><span class="font-icon icon iconfont icon-edit" style=""></span>Cherry<!----></a></li><li class="dropdown-item"><a href="/posts/dragonfruit" class="nav-link" aria-label="Dragon Fruit"><span class="font-icon icon iconfont icon-edit" style=""></span>Dragon Fruit<!----></a></li><li class="dropdown-item"><a href="/posts/tomato" class="nav-link" aria-label="/posts/tomato"><!---->/posts/tomato<!----></a></li><li class="dropdown-item"><a href="/posts/strawberry" class="nav-link" aria-label="/posts/strawberry"><!---->/posts/strawberry<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a href="https://theme-hope.vuejs.press/" rel="noopener noreferrer" target="_blank" aria-label="V2 Docs" class="nav-link"><span class="font-icon icon iconfont icon-note" style=""></span>V2 Docs<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div></nav><!--[--><!----><!--]--></div><div class="navbar-end"><!--[--><!----><!--]--><div class="nav-item"><div class="dropdown-wrapper i18n-dropdown"><button class="dropdown-title" type="button" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html" class="router-link-active router-link-exact-active nav-link active" aria-label="English"><!---->English<!----></a></li><li class="dropdown-item"><a href="/zh/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html" class="nav-link" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="nav-item"><a class="repo-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--[--><!----><!--]--><button class="toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span class="button-container"><span class="button-top"></span><span class="button-middle"></span><span class="button-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside class="sidebar" id="sidebar"><!--[--><!----><!--]--><ul class="sidebar-links"><li><!--[--><a href="/" class="nav-link sidebar-link sidebar-page" aria-label="Blog Home"><span class="font-icon icon iconfont icon-home" style=""></span>Blog Home<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><section class="sidebar-group"><p class="sidebar-heading clickable"><span class="font-icon icon iconfont icon-discover" style=""></span><a href="/demo/" class="title">Demo</a><!----></p><ul class="sidebar-links"><li><!--[--><a href="/demo/page.html" class="nav-link sidebar-link sidebar-page" aria-label="Page Config"><span class="font-icon icon iconfont icon-page" style=""></span>Page Config<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/demo/markdown.html" class="nav-link sidebar-link sidebar-page" aria-label="Markdown Enhance"><span class="font-icon icon iconfont icon-markdown" style=""></span>Markdown Enhance<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/demo/disable.html" class="nav-link sidebar-link sidebar-page" aria-label="Disabling layout and features"><span class="font-icon icon iconfont icon-config" style=""></span>Disabling layout and features<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/demo/encrypt.html" class="nav-link sidebar-link sidebar-page" aria-label="Encryption Article"><span class="font-icon icon iconfont icon-lock" style=""></span>Encryption Article<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li></ul></section></li><li><section class="sidebar-group"><p class="sidebar-heading active"><span class="font-icon icon iconfont icon-note" style=""></span><span class="title">Articles</span><!----></p><ul class="sidebar-links"><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">部署博客</span><span class="arrow end"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable active"><!----><span class="title">模型实践</span><span class="arrow down"></span></button><ul class="sidebar-links"><li><!--[--><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html" class="router-link-active router-link-exact-active nav-link active sidebar-link sidebar-page active" aria-label="从0开始搭建Auto-Encoder"><!---->从0开始搭建Auto-Encoder<!----></a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_1-搭建base-ae模型" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="1 搭建base_AE模型"><!---->1 搭建base_AE模型<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_2-搭建具体ae模型" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="2 搭建具体AE模型"><!---->2 搭建具体AE模型<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_3-调用模型进行训练-这里以网格搜索参数法为例" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="3 调用模型进行训练（这里以网格搜索参数法为例）"><!---->3 调用模型进行训练（这里以网格搜索参数法为例）<!----></a><ul class="sidebar-sub-headers"></ul></li><li class="sidebar-sub-header"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_4-根据编码器进行预测" class="router-link-active router-link-exact-active nav-link sidebar-link heading" aria-label="4 根据编码器进行预测"><!---->4 根据编码器进行预测<!----></a><ul class="sidebar-sub-headers"></ul></li></ul><!--]--></li></ul></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">深度学习</span><span class="arrow end"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">文章阅读</span><span class="arrow end"></span></button><!----></section></li><li><section class="sidebar-group"><button class="sidebar-heading clickable"><!----><span class="title">Python学习</span><span class="arrow end"></span></button><!----></section></li></ul></section></li><li><!--[--><a href="/intro.html" class="nav-link sidebar-link sidebar-page" aria-label="Intro Page"><span class="font-icon icon iconfont icon-info" style=""></span>Intro Page<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a href="/slides.html" class="nav-link sidebar-link sidebar-page" aria-label="Slide page"><span class="font-icon icon iconfont icon-slides" style=""></span>Slide page<!----></a><ul class="sidebar-sub-headers"></ul><!--]--></li></ul><!--[--><!----><!--]--></aside><!--[--><main class="page" id="main-content"><!--[--><!----><nav class="breadcrumb disable"></nav><div class="page-title"><h1><!---->从0开始搭建Auto-Encoder</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Huahuatii</span></span><span property="author" content="Huahuatii"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-03-18T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 9 min</span><meta property="timeRequired" content="PT9M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><span class="page-category-item category0 clickable" role="navigation">深度学习</span><span class="page-category-item category8 clickable" role="navigation">搭建模型</span><meta property="articleSection" content="深度学习,搭建模型"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><span class="page-tag-item tag1 clickable" role="navigation">Deep Learning</span><span class="page-tag-item tag7 clickable" role="navigation">Model Practice</span><span class="page-tag-item tag0 clickable" role="navigation">MLP</span><meta property="keywords" content="Deep Learning,Model Practice,MLP"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button class="print-button" title="print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_1-搭建base-ae模型" class="router-link-active router-link-exact-active toc-link level2">1 搭建base_AE模型</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_2-搭建具体ae模型" class="router-link-active router-link-exact-active toc-link level2">2 搭建具体AE模型</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_3-调用模型进行训练-这里以网格搜索参数法为例" class="router-link-active router-link-exact-active toc-link level2">3 调用模型进行训练（这里以网格搜索参数法为例）</a></li><!----><!--]--><!--[--><li class="toc-item"><a aria-current="page" href="/posts/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E8%B7%B5/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%80%E4%B8%AAMLP%E6%A8%A1%E5%9E%8B.html#_4-根据编码器进行预测" class="router-link-active router-link-exact-active toc-link level2">4 根据编码器进行预测</a></li><!----><!--]--></ul></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="从0开始搭建auto-encoder" tabindex="-1"><a class="header-anchor" href="#从0开始搭建auto-encoder" aria-hidden="true">#</a> 从0开始搭建Auto-Encoder</h1><p>搭建Auto-Encoder模型的时候，选择了更加结构化的搭建模式：</p><ol><li>搭建base_ae：这一步用来确定一个ae模型的基本结构会有哪些（其中有部分未必会用到）</li></ol><h2 id="_1-搭建base-ae模型" tabindex="-1"><a class="header-anchor" href="#_1-搭建base-ae模型" aria-hidden="true">#</a> 1 搭建base_AE模型</h2><ul><li>初始化</li><li>编码函数</li><li>解码函数</li><li>采样函数</li><li>生成函数</li><li>前向传播（抽象方法）</li><li>损失函数（抽象方法）</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;base_ae.py&#39;</span>
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> abc <span class="token keyword">import</span> abstractmethod  <span class="token comment"># 定义抽象方法</span>
<span class="token keyword">from</span> typing <span class="token keyword">import</span> TypeVar  <span class="token comment"># 定义数据类新的接口</span>
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Any
Tensor <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&#39;torch.tensor&#39;</span><span class="token punctuation">)</span>  <span class="token comment"># 定义泛型变量，表示一个 PyTorch 的 tensor</span>


<span class="token keyword">class</span> <span class="token class-name">BaseAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># 初始化神经网络模型的各个组件</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BaseAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>  <span class="token comment"># 定义一个编码过程</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>  <span class="token comment"># 定义一个解码过程</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> current_device<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义一个采样方法</span>
        <span class="token keyword">raise</span> RuntimeWarning<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义一个生成方法</span>
        <span class="token keyword">raise</span> NotImplementedError
        
    <span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># 定义初始化权重方法</span>
        <span class="token keyword">raise</span> NotImplementedError

    <span class="token decorator annotation punctuation">@abstractmethod</span>  <span class="token comment"># 装饰器，声明下面的方法为抽象方法</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义前向传播过程</span>
        <span class="token keyword">pass</span>

    <span class="token decorator annotation punctuation">@abstractmethod</span>
    <span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>  <span class="token comment"># 定义损失函数</span>
        <span class="token keyword">pass</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">细节补充</p><p><code>sample</code>：该方法通常需要从一个潜在空间中随机采样一个向量，然后使用解码器将该向量转换为一个输出。</p><p><code>generate</code> ：该方法是用来生成一个输出的，它接收一个潜在空间中的向量作为输入，然后使用解码器将这个向量转换为一个输出。</p><p><mark><code>abstractmethod</code></mark>：具有抽象方法的类叫做抽象类（不可被实例化），可以通过在方法定义中添加装饰器<code>@abstractmethod</code>来将一个方法标记为抽象方法，通常在父类中直接写pass（否则直接子类没有写抽象方法也会直接继承该方法），所以子类必须必须重新覆盖该抽象方法，才能被实例化。</p></div><h2 id="_2-搭建具体ae模型" tabindex="-1"><a class="header-anchor" href="#_2-搭建具体ae模型" aria-hidden="true">#</a> 2 搭建具体AE模型</h2><ul><li>继承</li><li>添加层</li><li>初始化权重</li><li></li></ul><details class="hint-container details"><summary>Details</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;ae.py&#39;</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> TypeVar
<span class="token keyword">from</span> model<span class="token punctuation">.</span>base_ae <span class="token keyword">import</span> BaseAE

Tensor <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&#39;torch.tensor&#39;</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">AE</span><span class="token punctuation">(</span>BaseAE<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>  <span class="token comment"># AE的构造函数</span>
                 input_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 latent_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 hidden_dims<span class="token punctuation">:</span> List <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
                 dop<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
                 noise_flag<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>latent_dim <span class="token operator">=</span> latent_dim
        self<span class="token punctuation">.</span>noise_flag <span class="token operator">=</span> noise_flag
        self<span class="token punctuation">.</span>dop <span class="token operator">=</span> dop

        <span class="token keyword">if</span> hidden_dims <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span>

        <span class="token comment"># build encoder</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 添加第一个隐藏层</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 循环添加中间隐藏层</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 添加最后一个隐藏层，输出维度为latent_dim</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 将以上层组成encoder</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        <span class="token comment"># build decoder(同encoder)</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        hidden_dims2 <span class="token operator">=</span> hidden_dims<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 确保encoder和decoder层对称</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>final_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 调用初始化权重方法</span>
        initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 编码输出隐藏层结果</span>
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>noise_flag <span class="token keyword">and</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span> <span class="token comment"># 判断噪音tag/训练模式-&gt;是否添加噪音</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>
                <span class="token builtin">input</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">)</span> <span class="token comment"># 隐藏层的位置添加0.05的噪音</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> latent_code

    <span class="token comment"># 解码输出最终结果</span>
    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>final_layer<span class="token punctuation">(</span>embed<span class="token punctuation">)</span>

        <span class="token keyword">return</span> outputs

    <span class="token comment"># 前向传播，返回三个参数[输入值，隐藏值，重构值]</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">,</span> z<span class="token punctuation">]</span>

    <span class="token comment"># 定义损失函数(MSE(均方误差))</span>
    <span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        recons <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        recons_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> recons<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> recons_loss

        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">&#39;recons_loss&#39;</span><span class="token punctuation">:</span> recons_loss<span class="token punctuation">}</span>

    <span class="token comment"># 定义采样的函数（在隐藏层随机采样）</span>
    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_samples<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> current_device<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
               <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_samples<span class="token punctuation">,</span> self<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span>

        z <span class="token operator">=</span> z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>current_device<span class="token punctuation">)</span>
        samples <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

        <span class="token keyword">return</span> samples

    
    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Initialize weights using Xavier initialization</span>
    <span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">细节补充</p></div></details><h2 id="_3-调用模型进行训练-这里以网格搜索参数法为例" tabindex="-1"><a class="header-anchor" href="#_3-调用模型进行训练-这里以网格搜索参数法为例" aria-hidden="true">#</a> 3 调用模型进行训练（这里以网格搜索参数法为例）</h2><ul><li>传入模型结构及参数</li><li>读取预测数据集</li><li>实例化模型</li><li>TensorBoard可视化训练过程（可选）</li><li>输出模型信息（可选）</li><li>训练过程</li></ul><details class="hint-container details"><summary>Details</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;train_ae.py&#39;</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> csv
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token punctuation">,</span> random_split
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler <span class="token keyword">import</span> StepLR

<span class="token keyword">from</span> math <span class="token keyword">import</span> ceil
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> ParameterGrid

<span class="token keyword">from</span> model<span class="token punctuation">.</span>ae <span class="token keyword">import</span> AE
<span class="token keyword">from</span> route<span class="token punctuation">.</span>route <span class="token keyword">import</span> set_seed<span class="token punctuation">,</span> read_uq_arr<span class="token punctuation">,</span> myDataset



<span class="token comment"># 设定随机种子</span>
set_seed<span class="token punctuation">(</span><span class="token number">2029</span><span class="token punctuation">)</span>

<span class="token comment"># gpu训练</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda:0&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>


<span class="token comment"># 网格参数</span>
param_grid  <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&#39;input_dim&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1126</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">502</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;learning_rate&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.002</span><span class="token punctuation">,</span> <span class="token number">0.0005</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;latent_dim&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;hidden_dims&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;dop&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;gamma&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token string">&#39;noise_flag&#39;</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>


<span class="token comment"># 加载数据</span>
BC32_uq1126 <span class="token operator">=</span> read_uq_arr<span class="token punctuation">(</span><span class="token string">&#39;BC32&#39;</span><span class="token punctuation">,</span> gene_num<span class="token operator">=</span><span class="token number">1126</span><span class="token punctuation">)</span>  <span class="token comment"># 读取数据</span>
data <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>BC32_uq1126<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  <span class="token comment"># 将arr数据转为tensor</span>
data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 将数据挪到GPU上</span>
dataset <span class="token operator">=</span> myDataset<span class="token punctuation">(</span>data<span class="token punctuation">)</span>  <span class="token comment"># 构建数据集</span>
train_size <span class="token operator">=</span> ceil<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.8</span><span class="token punctuation">)</span>  <span class="token comment"># 划分训练集大小</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">-</span> train_size  <span class="token comment"># 划分测试集大小</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> random_split<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 根据上述打乱数据集</span>

<span class="token comment"># 定义最优损失和参数</span>
best_loss <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">&#39;inf&#39;</span><span class="token punctuation">)</span>
best_params <span class="token operator">=</span> <span class="token boolean">None</span>

<span class="token comment"># 网格化搜索</span>
<span class="token keyword">for</span> params <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>ParameterGrid<span class="token punctuation">(</span>param_grid<span class="token punctuation">)</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                              batch_size<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                              shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>
                             batch_size<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                             shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment"># 使用当前参数训练模型</span>
    model <span class="token operator">=</span> AE<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;input_dim&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> latent_dim<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;latent_dim&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;hidden_dims&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dop<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;dop&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> noise_flag<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;noise_flag&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    
    <span class="token comment"># 打印训练信息</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\t----------------------------- INFO -------------------------------&quot;</span><span class="token punctuation">)</span>
    total_params <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Number of parameters: </span><span class="token interpolation"><span class="token punctuation">{</span>total_params<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Parameters: </span><span class="token interpolation"><span class="token punctuation">{</span>params<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;\t----------------------------- END --------------------------------&quot;</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 使用当前参数训练模型</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;learning_rate&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> model<span class="token punctuation">.</span>loss_function<span class="token punctuation">(</span><span class="token punctuation">)</span>
    scheduler <span class="token operator">=</span> StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span>params<span class="token punctuation">[</span><span class="token string">&#39;gamma&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>params<span class="token punctuation">[</span><span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 训练模型</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> inputs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> _ <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> model<span class="token punctuation">.</span>loss_function<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">]</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        train_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

        <span class="token comment"># 测试模型</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        test_loss <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> inputs <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> _ <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> model<span class="token punctuation">.</span>loss_function<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">]</span>
                test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            test_loss <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>

        <span class="token comment"># 更新学习率</span>
        scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 打印训练日志</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>
            <span class="token string-interpolation"><span class="token string">f&#39;Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token number">500</span><span class="token punctuation">}</span></span><span class="token string">, Train Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">, Test Loss: </span><span class="token interpolation"><span class="token punctuation">{</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">.6f</span><span class="token punctuation">}</span></span><span class="token string">&#39;</span></span>
        <span class="token punctuation">)</span>
        <span class="token comment"># 将训练结果保存为一个tsv文件，用于查看参数以及训练结果</span>
        <span class="token keyword">if</span> epoch<span class="token operator">+</span><span class="token number">1</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&#39;result.tsv&#39;</span><span class="token punctuation">,</span><span class="token string">&#39;a&#39;</span><span class="token punctuation">,</span>newline<span class="token operator">=</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
                fields <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&#39;gamma&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;dop&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;noise_flag&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;input_dim&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;hidden_dims&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;learning_rate&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;test_loss&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;latent_dim&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;batch_size&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">}</span>
                writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>DictWriter<span class="token punctuation">(</span>f<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">&#39;\t&#39;</span><span class="token punctuation">,</span> fieldnames<span class="token operator">=</span>fields<span class="token punctuation">)</span>
                <span class="token comment"># writer.writeheader()</span>
                result <span class="token operator">=</span> params<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
                result<span class="token punctuation">[</span><span class="token string">&#39;num_epochs&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> epoch
                result<span class="token punctuation">[</span><span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>train_loss<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
                result<span class="token punctuation">[</span><span class="token string">&#39;test_loss&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>test_loss<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
                writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span>result<span class="token punctuation">)</span>
                
    <span class="token comment"># 保存最好的参数组合</span>
    <span class="token keyword">if</span> test_loss <span class="token operator">&lt;</span> best_loss<span class="token punctuation">:</span>
        best_loss <span class="token operator">=</span> test_loss
        best_params <span class="token operator">=</span> params
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&#39;./saved/ae/ae_model.pt&#39;</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;最佳参数组合：&quot;</span><span class="token punctuation">,</span> best_params<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;最佳测试损失：&quot;</span><span class="token punctuation">,</span> best_loss<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>附`route.py`</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;route.py&#39;</span>
<span class="token keyword">import</span> scanpy <span class="token keyword">as</span> sc
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> pickle<span class="token punctuation">,</span> json
<span class="token keyword">from</span> typing <span class="token keyword">import</span> TypeVar<span class="token punctuation">,</span> List<span class="token punctuation">,</span> Any
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset

Array <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&quot;numpy.adarray&quot;</span><span class="token punctuation">)</span>
base_dir <span class="token operator">=</span> <span class="token string">&quot;/home/hht/Myapps/Transfer_Project/data/&quot;</span>


<span class="token comment"># 设定随机种子</span>
<span class="token keyword">def</span> <span class="token function">set_seed</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>


<span class="token comment"># 对array数据进行标准化</span>
<span class="token keyword">def</span> <span class="token function">get_normed_array</span><span class="token punctuation">(</span>arr<span class="token punctuation">:</span> Array<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Array<span class="token punctuation">:</span>
    np<span class="token punctuation">.</span>seterr<span class="token punctuation">(</span>divide<span class="token operator">=</span><span class="token string">&#39;ignore&#39;</span><span class="token punctuation">,</span> invalid<span class="token operator">=</span><span class="token string">&#39;ignore&#39;</span><span class="token punctuation">)</span>
    means <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>arr<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    stds <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>arr<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    stds <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>stds <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> stds<span class="token punctuation">)</span>
    standardized_arr <span class="token operator">=</span> <span class="token punctuation">(</span>arr <span class="token operator">-</span> means<span class="token punctuation">)</span> <span class="token operator">/</span> stds
    <span class="token keyword">return</span> standardized_arr


<span class="token comment"># 计算混淆矩阵</span>
<span class="token keyword">def</span> <span class="token function">confusion_matrix</span><span class="token punctuation">(</span>predicted_labels<span class="token punctuation">,</span> true_labels<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    cm <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    num_samples <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>predicted_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        cm<span class="token punctuation">[</span>predicted_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> true_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
        num_samples<span class="token punctuation">[</span>true_labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> cm<span class="token punctuation">,</span> num_samples


<span class="token comment"># 计算准确率</span>
<span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> cm<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># 计算召回率</span>
<span class="token keyword">def</span> <span class="token function">recall</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>cm<span class="token punctuation">)</span> <span class="token operator">/</span> cm<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">weighted_recall</span><span class="token punctuation">(</span>cm<span class="token punctuation">,</span> num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    r <span class="token operator">=</span> recall<span class="token punctuation">(</span>cm<span class="token punctuation">)</span>
    w <span class="token operator">=</span> num_samples <span class="token operator">/</span> num_samples<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    avg_recall <span class="token operator">=</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>r<span class="token punctuation">,</span> w<span class="token punctuation">)</span>
    <span class="token keyword">return</span> avg_recall


<span class="token comment"># 计算精确率</span>
<span class="token keyword">def</span> <span class="token function">precision</span><span class="token punctuation">(</span>cm<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>cm<span class="token punctuation">)</span> <span class="token operator">/</span> cm<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">weighted_precision</span><span class="token punctuation">(</span>cm<span class="token punctuation">,</span> num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_classes <span class="token operator">=</span> cm<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    precisions <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> num_samples<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            precisions<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> cm<span class="token punctuation">[</span>i<span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">/</span> cm<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    avg_precision <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>
        precisions <span class="token operator">*</span> num_samples<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span>
    <span class="token keyword">return</span> avg_precision


<span class="token comment"># 计算F1值</span>
<span class="token keyword">def</span> <span class="token function">f1_score</span><span class="token punctuation">(</span>precision<span class="token punctuation">,</span> recall<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span> <span class="token operator">*</span> precision <span class="token operator">*</span> recall <span class="token operator">/</span> <span class="token punctuation">(</span>precision <span class="token operator">+</span> recall<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">weighted_f1_score</span><span class="token punctuation">(</span>avg_precision<span class="token punctuation">,</span> avg_recall<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">2</span> <span class="token operator">*</span> avg_precision <span class="token operator">*</span> avg_recall <span class="token operator">/</span> <span class="token punctuation">(</span>avg_precision <span class="token operator">+</span> avg_recall<span class="token punctuation">)</span>


<span class="token comment"># 设定所需的common_gene</span>
<span class="token keyword">def</span> <span class="token function">choose_common_gene</span><span class="token punctuation">(</span>gene_num<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> gene_num <span class="token operator">==</span> <span class="token number">1729</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;Mart/common_uq_geneID_1729.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            cols_to_keep <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> gene_num <span class="token operator">==</span> <span class="token number">1126</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;Mart/common_uq_geneID_1126.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            cols_to_keep <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">elif</span> gene_num <span class="token operator">==</span> <span class="token number">1416</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;Mart/common_uq_geneID_1416.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            cols_to_keep <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">&quot;输入正确gene_num&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cols_to_keep


<span class="token comment"># 根据所需的特定基因读取数据的标准化arr</span>
<span class="token keyword">def</span> <span class="token function">read_uq_arr</span><span class="token punctuation">(</span>dataset_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> gene_num<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Array<span class="token punctuation">:</span>
    cols_to_keep <span class="token operator">=</span> choose_common_gene<span class="token punctuation">(</span>gene_num<span class="token punctuation">)</span>
    BC32_gex <span class="token operator">=</span> sc<span class="token punctuation">.</span>read_h5ad<span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC32/BC32_gex.h5ad&quot;</span><span class="token punctuation">)</span>
    BC32_uq1729_df <span class="token operator">=</span> BC32_gex<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> BC32_gex<span class="token punctuation">.</span>var<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>cols_to_keep<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_df<span class="token punctuation">(</span><span class="token punctuation">)</span>
    BC32_uq1729_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>BC32_uq1729_df<span class="token punctuation">)</span>
    BC32_uq1729 <span class="token operator">=</span> get_normed_array<span class="token punctuation">(</span>BC32_uq1729_arr<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC32&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> BC32_uq1729
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC15&#39;</span><span class="token punctuation">:</span>
        BC11_gex <span class="token operator">=</span> sc<span class="token punctuation">.</span>read_h5ad<span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/BC15_gex.h5ad&quot;</span><span class="token punctuation">)</span>
        BC11_uq_x_df <span class="token operator">=</span> BC11_gex<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                                BC11_gex<span class="token punctuation">.</span>var<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>cols_to_keep<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_df<span class="token punctuation">(</span><span class="token punctuation">)</span>
        BC11_uq1729_df <span class="token operator">=</span> BC11_uq_x_df<span class="token punctuation">.</span>reindex<span class="token punctuation">(</span>columns<span class="token operator">=</span>BC32_uq1729_df<span class="token punctuation">.</span>columns<span class="token punctuation">,</span>
                                              fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        BC11_uq1729_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>BC11_uq1729_df<span class="token punctuation">)</span>
        BC11_uq1729 <span class="token operator">=</span> get_normed_array<span class="token punctuation">(</span>BC11_uq1729_arr<span class="token punctuation">)</span>
        <span class="token keyword">return</span> BC11_uq1729

    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC11&#39;</span><span class="token punctuation">:</span>
        BC11_gex <span class="token operator">=</span> sc<span class="token punctuation">.</span>read_h5ad<span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/BC11/BC11_gex.h5ad&quot;</span><span class="token punctuation">)</span>
        BC11_uq_x_df <span class="token operator">=</span> BC11_gex<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>
                                BC11_gex<span class="token punctuation">.</span>var<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>cols_to_keep<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_df<span class="token punctuation">(</span><span class="token punctuation">)</span>
        BC11_uq1729_df <span class="token operator">=</span> BC11_uq_x_df<span class="token punctuation">.</span>reindex<span class="token punctuation">(</span>columns<span class="token operator">=</span>BC32_uq1729_df<span class="token punctuation">.</span>columns<span class="token punctuation">,</span>
                                              fill_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        BC11_uq1729_arr <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>BC11_uq1729_df<span class="token punctuation">)</span>
        BC11_uq1729 <span class="token operator">=</span> get_normed_array<span class="token punctuation">(</span>BC11_uq1729_arr<span class="token punctuation">)</span>
        <span class="token keyword">return</span> BC11_uq1729


<span class="token comment"># 读取数据标签</span>
<span class="token keyword">def</span> <span class="token function">read_label</span><span class="token punctuation">(</span>dataset_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC32&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC32/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            labels <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC15&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            labels <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dataset_name <span class="token operator">==</span> <span class="token string">&#39;BC11&#39;</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC15/BC11/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&#39;rb&#39;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            labels <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    labels<span class="token punctuation">,</span> classes <span class="token operator">=</span> pd<span class="token punctuation">.</span>factorize<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    <span class="token keyword">return</span> labels<span class="token punctuation">,</span> classes


<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>base_dir <span class="token operator">+</span> <span class="token string">&quot;BC32/lables.pickle&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>

    BC32_labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span>

    BC32_labels<span class="token punctuation">,</span> BC32_classes <span class="token operator">=</span> pd<span class="token punctuation">.</span>factorize<span class="token punctuation">(</span>BC32_labels<span class="token punctuation">)</span>



<span class="token keyword">class</span> <span class="token class-name">myDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>index<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details></details><h2 id="_4-根据编码器进行预测" tabindex="-1"><a class="header-anchor" href="#_4-根据编码器进行预测" aria-hidden="true">#</a> 4 根据编码器进行预测</h2><ul><li>继承</li><li>添加层</li><li>初始化权重</li><li></li></ul><details class="hint-container details"><summary>Details</summary><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token string">&#39;ae.py&#39;</span>
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> TypeVar
<span class="token keyword">from</span> model<span class="token punctuation">.</span>base_ae <span class="token keyword">import</span> BaseAE

Tensor <span class="token operator">=</span> TypeVar<span class="token punctuation">(</span><span class="token string">&#39;torch.tensor&#39;</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">AE</span><span class="token punctuation">(</span>BaseAE<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>  <span class="token comment"># AE的构造函数</span>
                 input_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 latent_dim<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 hidden_dims<span class="token punctuation">:</span> List <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
                 dop<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
                 noise_flag<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>latent_dim <span class="token operator">=</span> latent_dim
        self<span class="token punctuation">.</span>noise_flag <span class="token operator">=</span> noise_flag
        self<span class="token punctuation">.</span>dop <span class="token operator">=</span> dop

        <span class="token keyword">if</span> hidden_dims <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden_dims <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span>

        <span class="token comment"># build encoder</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 添加第一个隐藏层</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 循环添加中间隐藏层</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 添加最后一个隐藏层，输出维度为latent_dim</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span>
        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> latent_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 将以上层组成encoder</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        <span class="token comment"># build decoder(同encoder)</span>
        modules <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>latent_dim<span class="token punctuation">,</span> hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                          nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        hidden_dims2 <span class="token operator">=</span> hidden_dims<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 确保encoder和decoder层对称</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            modules<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>modules<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>final_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dop<span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dims2<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># 调用初始化权重方法</span>
        initialize_weights<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 编码输出隐藏层结果</span>
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>noise_flag <span class="token keyword">and</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span> <span class="token comment"># 判断噪音tag/训练模式-&gt;是否添加噪音</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>
                <span class="token builtin">input</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">)</span> <span class="token comment"># 隐藏层的位置添加0.05的噪音</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            latent_code <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> latent_code

    <span class="token comment"># 解码输出最终结果</span>
    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">:</span> Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>final_layer<span class="token punctuation">(</span>embed<span class="token punctuation">)</span>

        <span class="token keyword">return</span> outputs

    <span class="token comment"># 前向传播，返回三个参数[输入值，隐藏值，重构值]</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">:</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">,</span> z<span class="token punctuation">]</span>

    <span class="token comment"># 定义损失函数(MSE(均方误差))</span>
    <span class="token keyword">def</span> <span class="token function">loss_function</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        recons <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        recons_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>mse_loss<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> recons<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> recons_loss

        <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&#39;loss&#39;</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span> <span class="token string">&#39;recons_loss&#39;</span><span class="token punctuation">:</span> recons_loss<span class="token punctuation">}</span>

    <span class="token comment"># 定义采样的函数（在隐藏层随机采样）</span>
    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_samples<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> current_device<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
               <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_samples<span class="token punctuation">,</span> self<span class="token punctuation">.</span>latent_dim<span class="token punctuation">)</span>

        z <span class="token operator">=</span> z<span class="token punctuation">.</span>to<span class="token punctuation">(</span>current_device<span class="token punctuation">)</span>
        samples <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>

        <span class="token keyword">return</span> samples

    
    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> Tensor<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Tensor<span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Initialize weights using Xavier initialization</span>
    <span class="token keyword">def</span> <span class="token function">initialize_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> net<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>zeros_<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">细节补充</p></div></details></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/docs/posts/模型实践/从头开始写一个MLP模型.md" rel="noopener noreferrer" target="_blank" aria-label="Edit this page on GitHub" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><!----><!----></div></footer><!----><div class="giscus-wrapper input-top" id="comment" style="display:block;"><div class="loading-icon-wrapper" style="display:flex;align-items:center;justify-content:center;height:96px"><svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" preserveAspectRatio="xMidYMid" viewBox="25 25 50 50"><animateTransform attributeName="transform" type="rotate" dur="2s" keyTimes="0;1" repeatCount="indefinite" values="0;360"></animateTransform><circle cx="50" cy="50" r="20" fill="none" stroke="currentColor" stroke-width="4" stroke-linecap="round"><animate attributeName="stroke-dasharray" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="1,200;90,200;1,200"></animate><animate attributeName="stroke-dashoffset" dur="1.5s" keyTimes="0;0.5;1" repeatCount="indefinite" values="0;-35px;-125px"></animate></circle></svg></div></div><!----><!--]--></main><!--]--><footer class="footer-wrapper"><div class="footer">Default footer</div><div class="copyright">Copyright © 2023 Huahuatii</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-372f1543.js" defer></script>
  </body>
</html>
